{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed3ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from models import MultiLayeredPerceptron as mlp\n",
    "from lora_models import LoRAModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db7b11",
   "metadata": {},
   "source": [
    "# Testing LoRAModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9002ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(size=(4, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45804bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayeredPerceptron(\n",
      "  (linear_0): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (dropout_0): Dropout(p=0.2, inplace=False)\n",
      "  (relu_0): ReLU(inplace=True)\n",
      "  (linear_1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "  (relu_1): ReLU(inplace=True)\n",
      "  (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "  (relu_2): ReLU(inplace=True)\n",
      "  (output): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Num trainable/non-trainable parameters in model: 932362/0\n"
     ]
    }
   ],
   "source": [
    "model = mlp()\n",
    "print(model)\n",
    "\n",
    "num_trainable_parameters_in_model = 0\n",
    "num_non_trainable_parameters_in_model = 0\n",
    "for parameter in model.parameters():\n",
    "    if parameter.requires_grad:\n",
    "        num_trainable_parameters_in_model += parameter.numel()\n",
    "    else:\n",
    "        num_non_trainable_parameters_in_model += parameter.numel()\n",
    "print(f'Num trainable/non-trainable parameters in model: {num_trainable_parameters_in_model}/{num_non_trainable_parameters_in_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23909c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0385, -0.0739, -0.0023, -0.0079,  0.0436, -0.0159,  0.0154,  0.0247,\n",
       "         -0.0538,  0.0112],\n",
       "        [-0.0350, -0.0507,  0.0483, -0.0785, -0.0365, -0.0622,  0.0421,  0.0132,\n",
       "         -0.0086, -0.0257],\n",
       "        [-0.0182, -0.0469,  0.0529, -0.0721,  0.0079, -0.0915,  0.0192, -0.0106,\n",
       "         -0.0646,  0.0350],\n",
       "        [-0.0076, -0.0508, -0.0328, -0.0568,  0.0235, -0.0257,  0.0242, -0.0563,\n",
       "         -0.0564,  0.0637]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "# model.linear_0(x)\n",
    "# model.linear_1(model.linear_0(x))\n",
    "# model.linear_2(model.linear_1(model.linear_0(x)))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1b7db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayeredPerceptron(\n",
      "  (linear_0): LoRALinear(Linear(in_features=784, out_features=512, bias=True) + ((α=2/r=4) × Adapter(in_features=784, rank=4, out_features=512, delta_bias=True)))\n",
      "  (dropout_0): Dropout(p=0.2, inplace=False)\n",
      "  (relu_0): ReLU(inplace=True)\n",
      "  (linear_1): LoRALinear(Linear(in_features=512, out_features=512, bias=True) + ((α=2/r=4) × Adapter(in_features=512, rank=4, out_features=512, delta_bias=True)))\n",
      "  (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "  (relu_1): ReLU(inplace=True)\n",
      "  (linear_2): LoRALinear(Linear(in_features=512, out_features=512, bias=True) + ((α=2/r=4) × Adapter(in_features=512, rank=4, out_features=512, delta_bias=True)))\n",
      "  (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "  (relu_2): ReLU(inplace=True)\n",
      "  (output): LoRALinear(Linear(in_features=512, out_features=10, bias=True) + ((α=2/r=4) × Adapter(in_features=512, rank=4, out_features=10, delta_bias=True)))\n",
      ")\n",
      "Num trainable/non-trainable parameters in LoRA Model: 17010/932370\n"
     ]
    }
   ],
   "source": [
    "lora_model = LoRAModel()\n",
    "lora_model.add_base_model(base_model=model)\n",
    "lora_config = {\n",
    "    'rank': 4,\n",
    "    'alpha': 2,\n",
    "    'delta_bias': True\n",
    "}\n",
    "lora_target_module_names = ['linear_*', 'output']\n",
    "lora_model.build_new_adapter(lora_target_module_names=lora_target_module_names, lora_config=lora_config)\n",
    "print(lora_model)\n",
    "\n",
    "num_trainable_parameters_in_lora_model = 0\n",
    "num_non_trainable_parameters_in_lora_model = 0\n",
    "for parameter in lora_model.parameters():\n",
    "    if parameter.requires_grad:\n",
    "        num_trainable_parameters_in_lora_model += parameter.numel()\n",
    "    else:\n",
    "        num_non_trainable_parameters_in_lora_model += parameter.numel()\n",
    "print(f'Num trainable/non-trainable parameters in LoRA Model: {num_trainable_parameters_in_lora_model}/{num_non_trainable_parameters_in_lora_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfb457e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_0', 'linear_1', 'linear_2', 'output']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.lora_module_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cdd7600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0385, -0.0739, -0.0023, -0.0079,  0.0436, -0.0159,  0.0154,  0.0247,\n",
       "         -0.0538,  0.0112],\n",
       "        [-0.0350, -0.0507,  0.0483, -0.0785, -0.0365, -0.0622,  0.0421,  0.0132,\n",
       "         -0.0086, -0.0257],\n",
       "        [-0.0182, -0.0469,  0.0529, -0.0721,  0.0079, -0.0915,  0.0192, -0.0106,\n",
       "         -0.0646,  0.0350],\n",
       "        [-0.0076, -0.0508, -0.0328, -0.0568,  0.0235, -0.0257,  0.0242, -0.0563,\n",
       "         -0.0564,  0.0637]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.disable_adapter()\n",
    "lora_model.eval()\n",
    "# lora_model.base_model.linear_0(x)\n",
    "# lora_model.base_model.linear_1(lora_model.base_model.linear_0(x))\n",
    "# lora_model.base_model.linear_1(lora_model.base_model.linear_1(lora_model.base_model.linear_0(x)))\n",
    "lora_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effb1659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -87049.5547, -106407.2656,  -21747.7207, -179911.1250,  -81629.9609,\n",
       "          234928.7500,   25671.4902,   54547.1289, -157710.0938,  190898.9062],\n",
       "        [  -7636.5898,  -26221.3164,  -26860.4238,   -5352.1958,  -25560.0000,\n",
       "           57498.2383,   -2451.0200,  -42766.2734,  -26559.9395,   29143.9199],\n",
       "        [ -94373.1641, -124760.3281,  -61997.8594, -174638.4688,  -93002.6484,\n",
       "          293159.3438,    9188.9229,   17679.0898, -181154.5625,  203632.7344],\n",
       "        [ -23100.7070,  -16771.1582,   10287.8262,  -41455.0312,  -15927.0791,\n",
       "           38074.0742,    8886.5898,   21427.4922,  -29487.0918,   41675.3633]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.enable_adapter()\n",
    "lora_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5398cebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -87049.5625, -106407.2500,  -21747.7402, -179911.0938,  -81629.9688,\n",
       "          234928.7188,   25671.5000,   54547.1172, -157710.1250,  190898.9062],\n",
       "        [  -7636.5918,  -26221.3125,  -26860.3906,   -5352.2051,  -25560.0176,\n",
       "           57498.2148,   -2450.9971,  -42766.2617,  -26559.9336,   29143.9238],\n",
       "        [ -94373.1953, -124760.3359,  -61997.8320, -174638.5625,  -93002.6094,\n",
       "          293159.3750,    9188.8838,   17679.1406, -181154.5938,  203632.7500],\n",
       "        [ -23100.6914,  -16771.1562,   10287.8164,  -41455.0469,  -15927.0859,\n",
       "           38074.0859,    8886.5957,   21427.4844,  -29487.0820,   41675.3672]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model = lora_model.get_merged_model()\n",
    "merged_model.eval()\n",
    "merged_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a5679-dcda-4924-b922-6fc5edb4c160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
