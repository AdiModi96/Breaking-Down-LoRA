{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed3ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from models import MultiLayeredPerceptron as mlp\n",
    "from lora_models import LoRAModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db7b11",
   "metadata": {},
   "source": [
    "# Testing LoRAModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc0618f-4ad8-4a86-94af-ec02a1707dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9002ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(size=(4, 784))\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45804bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayeredPerceptron(\n",
      "  (linear_0): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (dropout_0): Dropout(p=0.2, inplace=False)\n",
      "  (relu_0): ReLU(inplace=True)\n",
      "  (linear_1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "  (relu_1): ReLU(inplace=True)\n",
      "  (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "  (relu_2): ReLU(inplace=True)\n",
      "  (output): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Num trainable/non-trainable parameters in model: 932362/0\n"
     ]
    }
   ],
   "source": [
    "model = mlp()\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "num_trainable_parameters_in_model = 0\n",
    "num_non_trainable_parameters_in_model = 0\n",
    "for parameter in model.parameters():\n",
    "    if parameter.requires_grad:\n",
    "        num_trainable_parameters_in_model += parameter.numel()\n",
    "    else:\n",
    "        num_non_trainable_parameters_in_model += parameter.numel()\n",
    "print(f'Num trainable/non-trainable parameters in model: {num_trainable_parameters_in_model}/{num_non_trainable_parameters_in_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e23909c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0837, -0.0374, -0.0703,  0.0148, -0.0619,  0.0325,  0.0116,  0.0557,\n",
       "         -0.0203,  0.0228],\n",
       "        [-0.0030, -0.0545, -0.0350,  0.0060, -0.0148,  0.0459,  0.0160,  0.0443,\n",
       "          0.0676, -0.0091],\n",
       "        [ 0.0846, -0.0083, -0.0556,  0.0164, -0.0621,  0.0111,  0.0044,  0.0324,\n",
       "          0.0208,  0.0181],\n",
       "        [ 0.0436, -0.0069, -0.0604,  0.0010, -0.0319,  0.0533,  0.0149,  0.0526,\n",
       "         -0.0134,  0.0044]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "# model.linear_0(x)\n",
    "# model.linear_1(model.linear_0(x))\n",
    "# model.linear_2(model.linear_1(model.linear_0(x)))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f599d527-ef5a-470a-9fc1-25d9ad370538",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = {\n",
    "    'linear_*': {\n",
    "        'rank': 4,\n",
    "        'alpha': 2,\n",
    "        'delta_bias': True\n",
    "    },\n",
    "    'output': {\n",
    "        'rank': 4,\n",
    "        'alpha': 2,\n",
    "        'delta_bias': True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c1b7db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRAModel(\n",
      "  (base_model): MultiLayeredPerceptron(\n",
      "    (linear_0): LoRALinear(Linear(in_features=784, out_features=512, bias=True) + ((α=2.0/r=4) × Adapter(in_features=784, rank=4, out_features=512, delta_bias=True)))\n",
      "    (dropout_0): Dropout(p=0.2, inplace=False)\n",
      "    (relu_0): ReLU(inplace=True)\n",
      "    (linear_1): LoRALinear(Linear(in_features=512, out_features=512, bias=True) + ((α=2.0/r=4) × Adapter(in_features=512, rank=4, out_features=512, delta_bias=True)))\n",
      "    (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "    (relu_1): ReLU(inplace=True)\n",
      "    (linear_2): LoRALinear(Linear(in_features=512, out_features=512, bias=True) + ((α=2.0/r=4) × Adapter(in_features=512, rank=4, out_features=512, delta_bias=True)))\n",
      "    (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "    (relu_2): ReLU(inplace=True)\n",
      "    (output): LoRALinear(Linear(in_features=512, out_features=10, bias=True) + ((α=2.0/r=4) × Adapter(in_features=512, rank=4, out_features=10, delta_bias=True)))\n",
      "  )\n",
      ")\n",
      "Num trainable/non-trainable parameters in LoRA Model: 17010/932370\n"
     ]
    }
   ],
   "source": [
    "lora_model = LoRAModel(model, lora_config)\n",
    "print(lora_model)\n",
    "\n",
    "num_trainable_parameters_in_lora_model = 0\n",
    "num_non_trainable_parameters_in_lora_model = 0\n",
    "for parameter in lora_model.parameters():\n",
    "    if parameter.requires_grad:\n",
    "        num_trainable_parameters_in_lora_model += parameter.numel()\n",
    "    else:\n",
    "        num_non_trainable_parameters_in_lora_model += parameter.numel()\n",
    "print(f'Num trainable/non-trainable parameters in LoRA Model: {num_trainable_parameters_in_lora_model}/{num_non_trainable_parameters_in_lora_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cdd7600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0837, -0.0374, -0.0703,  0.0148, -0.0619,  0.0325,  0.0116,  0.0557,\n",
       "         -0.0203,  0.0228],\n",
       "        [-0.0030, -0.0545, -0.0350,  0.0060, -0.0148,  0.0459,  0.0160,  0.0443,\n",
       "          0.0676, -0.0091],\n",
       "        [ 0.0846, -0.0083, -0.0556,  0.0164, -0.0621,  0.0111,  0.0044,  0.0324,\n",
       "          0.0208,  0.0181],\n",
       "        [ 0.0436, -0.0069, -0.0604,  0.0010, -0.0319,  0.0533,  0.0149,  0.0526,\n",
       "         -0.0134,  0.0044]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.disable_adapter()\n",
    "lora_model.eval()\n",
    "# lora_model.base_model.linear_0(x)\n",
    "# lora_model.base_model.linear_1(lora_model.base_model.linear_0(x))\n",
    "# lora_model.base_model.linear_1(lora_model.base_model.linear_1(lora_model.base_model.linear_0(x)))\n",
    "lora_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effb1659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0770, -0.0724, -0.0822, -0.0045, -0.1111, -0.0148,  0.0157,  0.0833,\n",
       "         -0.0413,  0.0405],\n",
       "        [ 0.0415, -0.0679, -0.0668,  0.0092, -0.0389,  0.0161, -0.0070,  0.0340,\n",
       "          0.0932,  0.0049],\n",
       "        [ 0.0981, -0.0483, -0.0365, -0.0075, -0.1120, -0.0235,  0.0196,  0.0278,\n",
       "          0.0033,  0.0180],\n",
       "        [ 0.0289, -0.0766, -0.1286, -0.0011, -0.0875,  0.0370,  0.0016,  0.0805,\n",
       "         -0.0231,  0.0235]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.enable_adapter()\n",
    "lora_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5398cebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0770, -0.0724, -0.0822, -0.0045, -0.1111, -0.0148,  0.0157,  0.0833,\n",
       "         -0.0413,  0.0405],\n",
       "        [ 0.0415, -0.0679, -0.0668,  0.0092, -0.0389,  0.0161, -0.0070,  0.0340,\n",
       "          0.0932,  0.0049],\n",
       "        [ 0.0981, -0.0483, -0.0365, -0.0075, -0.1120, -0.0235,  0.0196,  0.0278,\n",
       "          0.0033,  0.0180],\n",
       "        [ 0.0289, -0.0766, -0.1286, -0.0011, -0.0875,  0.0370,  0.0016,  0.0805,\n",
       "         -0.0231,  0.0235]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model = lora_model.get_merged_model()\n",
    "merged_model.eval()\n",
    "merged_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a5679-dcda-4924-b922-6fc5edb4c160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
